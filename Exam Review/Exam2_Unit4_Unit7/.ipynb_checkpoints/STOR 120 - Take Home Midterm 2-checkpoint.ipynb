{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STOR 120: Take Home Midterm 2\n",
    "\n",
    "60 points total\n",
    "\n",
    "**Due:** Wednesday, March 30th to Gradescope before the start of class time.\n",
    "\n",
    "    Section 001: 12:20pm\n",
    "    Section 002:  1:25pm\n",
    "  \n",
    "**Directions:** The exam is open book, notes, course materials, internet, and all things that are not direct communication with others. Just as with all course assignments, you will submit exams to Gradescope as Jupyter Notebooks with the ipynb file extension. To receive full credit, you should show all of your code used to answer each question. Make sure to view your submission in Gradescope and verify that it is the correct file and has the format that you intended it to have, including all code being shown and run.\n",
    "\n",
    "Come to office hours if you have specific questions regarding the exam. Due to the large class sizes, individual questions sent via email are not possible to answer for all students. Please refrain from posting public questions to Piazza before the exam is due.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Run the cell below to import the needed modules**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datascience import *\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random as rd\n",
    "from collections import Counter\n",
    "from random import choices\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('fivethirtyeight')\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter('ignore', FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. The Birthday Paradox *(20 points total)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose that you are at a party and there are exactly 23 people are in the room. What are the chances that at least 2 of the people share the same birthday (not considering the year)? Suprising to most, the probability is actually greater than 50%! This is refered to as the *Birthday Paradox*, although it's only a “paradox” because our brains can’t handle the compounding power of exponents. To investigate this \"paradox\", you are going to simulate it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1.1.** Construct an array `days` with 365 elements, numbered 1 through 365. We'll use this as our possible birthdays (not considering leap years). Then write a function `My_Party` that takes in one argument, the size of the party `n`, simulates a party of size `n` with `n` randomly selected birthdays, and returns a value of `1` if at least two people at the party have the same birthday. If no one at the party has the same birthday, the function should return `0`. *(7 pts)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([126, 165, 290, 139, 169,  24, 323, 116, 175, 319, 282, 351,  47,\n",
       "       262,  37, 250, 297, 322, 123, 347,  42, 204, 182])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "days = np.arange(1,366, 1)\n",
    "days_list = []\n",
    "\n",
    "for x in np.arange(0, len(days),1): \n",
    "    days_list.append(days[x])\n",
    "    \n",
    "party_size = 23\n",
    "\n",
    "party_people_birthdays = np.random.choice(days_list, size=party_size, replace = True)\n",
    "\n",
    "party_people_birthdays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[126,\n",
       " 165,\n",
       " 290,\n",
       " 139,\n",
       " 169,\n",
       " 24,\n",
       " 323,\n",
       " 116,\n",
       " 175,\n",
       " 319,\n",
       " 282,\n",
       " 351,\n",
       " 47,\n",
       " 262,\n",
       " 37,\n",
       " 250,\n",
       " 297,\n",
       " 322,\n",
       " 123,\n",
       " 347,\n",
       " 42,\n",
       " 204,\n",
       " 182]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "party_people_birthdays_list = []\n",
    "\n",
    "# Make the array a list \n",
    "for y in np.arange(party_size):\n",
    "    party_people_birthdays_list.append(party_people_birthdays[y])\n",
    "    \n",
    "party_people_birthdays_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{126: 1, 165: 1, 290: 1, 139: 1, 169: 1, 24: 1, 323: 1, 116: 1, 175: 1, 319: 1, 282: 1, 351: 1, 47: 1, 262: 1, 37: 1, 250: 1, 297: 1, 322: 1, 123: 1, 347: 1, 42: 1, 204: 1, 182: 1}\n"
     ]
    }
   ],
   "source": [
    "res = {}\n",
    "\n",
    "for i in party_people_birthdays_list:\n",
    "    res[i] = party_people_birthdays_list.count(i)\n",
    "    \n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# If there is a key in this above dictionary that is equal to or greater than 2, then we want to add 1 to a counter \n",
    "\n",
    "count = 0 \n",
    "for key in res:\n",
    "    if res[key] >= 2: \n",
    "        count = 1\n",
    "    else: \n",
    "        count = count + 0 \n",
    "        \n",
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Put it all together \n",
    "days = np.arange(1,366, 1)\n",
    "days_list = []\n",
    "\n",
    "for x in np.arange(0, len(days),1): \n",
    "    days_list.append(days[x])\n",
    "    \n",
    "def My_Party(party_size):\n",
    "    party_people_birthdays = np.random.choice(days_list, size=party_size, replace = True)\n",
    "    party_people_birthdays_list = []\n",
    "    \n",
    "    # Make the array a list \n",
    "    for y in np.arange(party_size):\n",
    "        party_people_birthdays_list.append(party_people_birthdays[y])\n",
    "    \n",
    "    res = {}\n",
    "    \n",
    "    for i in party_people_birthdays_list:\n",
    "        res[i] = party_people_birthdays_list.count(i)\n",
    "    \n",
    "    # print(res) \n",
    "    # Uncomment \"print(res)\" if you want to confirm things are working \n",
    "    \n",
    "    count = 0 \n",
    "    \n",
    "    for key in res:\n",
    "        if res[key] >= 2: \n",
    "            count = 1\n",
    "        else: \n",
    "            count = count + 0 \n",
    "    return(count)\n",
    "    \n",
    "# Do not delete or change the below line of code\n",
    "My_Party(23)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1.2** Perform a simulation that simulates 10,000 parties of 23 people with randomly selected birthdays. In what proportion of these parties did at least two people have the same birthday? *(3 pts)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5043"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simulation_data = []\n",
    "simulations = 100000\n",
    "\n",
    "for x in np.arange(simulations):\n",
    "    simulation_data.append(My_Party(23))\n",
    "\n",
    "proportion_yes_2_same_bdays = simulation_data.count(1)/simulations\n",
    "proportion_yes_2_same_bdays"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1.3** Now let's see how we can calculate this mathematically for a smaller party size. Suppose that you are at a small get together with only 5 people. Calculate (using algebra and not a simulation) the probability of having a party of 5 people where at least two people have the same birthday. Assign this value (with algebra showing how you calculated this answer) to `Birthday_Paradox_for_5`. *(2 pts)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The question is asking for us to NOT use the function, but to calculate \"by hand\" how to find the: \n",
    "# probability of a party of 5 people where at least 2 people have the same birthday \n",
    "\n",
    "# Probability that no one has the same birthday, excluding leap years \n",
    "no_same_bday = (365/365) * (364/365) * (363/365) * (362/365) * (361/365)\n",
    "\n",
    "# Probability at least 2 share bday \n",
    "at_least_2_bday = 1 - no_same_bday"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.02713557369979347"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Birthday_Paradox_for_5 = at_least_2_bday\n",
    "Birthday_Paradox_for_5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1.4** Reusing much of the code from question 1.2, write a function `Many_of_My_Parties` that performs a simulation that simulates 10,000 parties of size `n` people with randomly selected birthdays. The function should return the proportion of these parties where at least two people have the same birthday. *(4 pts)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.02738"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def Many_of_My_Parties(party_size): \n",
    "    simulation_data = []\n",
    "    simulations = 100000\n",
    "\n",
    "    for x in np.arange(simulations):\n",
    "        simulation_data.append(My_Party(party_size))\n",
    "\n",
    "    proportion_yes_2_same_bdays = simulation_data.count(1)/simulations\n",
    "    return(proportion_yes_2_same_bdays)\n",
    "\n",
    "# Do not delete or change the below line of code\n",
    "Many_of_My_Parties(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1.5** Construct a table `Birthday_Paradox_for_n` containing a column `Size of Party` for party sizes of 5, 10, 15, 20, 25, 30, 35, 40, and 45. A second column `At Least Two` should contain your simulated probabilities for parties of the `Size of the Party` having at least two people with the same birthday. *(4 pts)*\n",
    "\n",
    "Note: This code may take a few more seconds to run than our typical simulations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 5, 10, 15, 20, 25, 30, 35, 40, 45])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.arange(5,46,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_28392/4111527778.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m Birthday_Paradox_for_n = {\"Size of Party\": np.arange(5,46,5), \n\u001b[1;32m----> 2\u001b[1;33m                           \"At Least Two\": [Many_of_My_Parties(i) for i in np.arange(5,46,5)]}\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# # Do not delete or change the below line of code\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_28392/4111527778.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      1\u001b[0m Birthday_Paradox_for_n = {\"Size of Party\": np.arange(5,46,5), \n\u001b[1;32m----> 2\u001b[1;33m                           \"At Least Two\": [Many_of_My_Parties(i) for i in np.arange(5,46,5)]}\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# # Do not delete or change the below line of code\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_28392/1280388674.py\u001b[0m in \u001b[0;36mMany_of_My_Parties\u001b[1;34m(party_size)\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msimulations\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m         \u001b[0msimulation_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mMy_Party\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparty_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mproportion_yes_2_same_bdays\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msimulation_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0msimulations\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_28392/1909039460.py\u001b[0m in \u001b[0;36mMy_Party\u001b[1;34m(party_size)\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mMy_Party\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparty_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m     \u001b[0mparty_people_birthdays\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdays_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mparty_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreplace\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m     \u001b[0mparty_people_birthdays_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "Birthday_Paradox_for_n = tbl.with_columns(\"Size of Party\", [ 5, 10, 15, 20, 25, 30, 35, 40, 45], \n",
    "                          \"At Least Two\", [Many_of_My_Parties(5), Many_of_My_Parties(10), \n",
    "                                           Many_of_My_Parties(15), Many_of_My_Parties(20), \n",
    "                                           Many_of_My_Parties(25), Many_of_My_Parties(30),\n",
    "                                           Many_of_My_Parties(35), Many_of_My_Parties(40),\n",
    "                                           Many_of_My_Parties(45)])\n",
    "\n",
    "\n",
    "\n",
    "# # Do not delete or change the below line of code\n",
    "# Birthday_Paradox_for_n.plot('Size of Party')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Which Justin? *(40 points total)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The table `Which_Justin` contains a random sample of data collected from Instagram posts made by three famous Justins: Bieber, Trudeau, and Timberlake. Each row of the table is an Instagram post, with variables such as the number of likes, comments, hashtags, characters, words, emojis, and mentions. Run the cell below to load the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Which_Justin_df = pd.read_csv('Which_Justin_120.csv')\n",
    "Which_Justin_df[\"username\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "**Question 2.1** How similar or different do we expect the attribues of the posts by these Justins to be? You may believe that the average number of emojis used in Instagram posts by Justin Beiber is greater than that of Justin Trudeau. Let's perform a hypothesis test to test this claim with our sample data. For this test, we should use the hypotheses below. *(12 pts)*\n",
    "\n",
    "**Null Hypothesis:** The average number of emojis used in Justin Bieber's Instagram posts is equal to the average number of emojis used in Justin Trudeau's Instagram posts      \n",
    "    \n",
    "**Alternative Hypothesis**: The average number of emojis used in Justin Bieber's Instagram posts is greater than the average number of emojis used in Justin Trudeau's Instagram posts\n",
    "\n",
    "Perform a hypotheses test to test the above hypotheses. **To receive full credit you should:**\n",
    "\n",
    "1. Choose an appropriate test statistic\n",
    "\n",
    "2. Find the value of the observed test statistic\n",
    "\n",
    "3. Assume the null hypothesis is true and sample from the theoretical population under the null hypothesis and obtain the simulated test statistic. Repeat this 1000 times.\n",
    "\n",
    "4. Plot your simulated test statistics in a histogram along with the observed test statistic\n",
    "\n",
    "5. Calculate the p-value based off of your observed and simulated test statistics\n",
    "\n",
    "6. Use the p-value to draw a conclusion and explain the conclusion using simple, non-technical language in the context of the problem with complete sentences\n",
    "\n",
    "You may do this in as many lines as needed, and may add cells as well. You can (should) use functions that we have used in class, homework, labs, or from the text!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notes\n",
    "**What I want:**  We want to run a difference in means between the average number of emojis used inJB's IG posts vs JT's IG posts \n",
    "\n",
    "### A/B Testing Steps: \n",
    "1. Define a null and alternate model \n",
    "\n",
    "**Null Hypothesis:** The average number of emojis used in Justin Bieber's Instagram posts is equal to the average number of emojis used in Justin Trudeau's Instagram posts      \n",
    "    \n",
    "**Alternative Hypothesis**: The average number of emojis used in Justin Bieber's Instagram posts is greater than the average number of emojis used in Justin Trudeau's Instagram posts\n",
    "\n",
    "2. Choose a test statistic (typically the difference in means between two categories)\n",
    "\n",
    "**What I want:**  We want to run a difference in means between the average number of emojis used inJB's IG posts vs JT's IG posts \n",
    "\n",
    "**Compare** \n",
    "\n",
    "    - (A): n_emojies in JB IG Posts\n",
    "    \n",
    "    - (B): n_emojies in JT IG Posts\n",
    "\n",
    "Is the difference due to chance alone? We are assuming there is no difference and we want to test if there is a difference. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a new smaller table:\n",
    "JB_JT_df = Which_Justin_df[(Which_Justin_df[\"username\"] == \"justinbieber\") | (Which_Justin_df[\"username\"] == \"justinpjtrudeau\")]\n",
    "smaller = JB_JT_df[[\"username\", \"n_emojis\"]]\n",
    "smaller_groups = smaller.groupby(\"username\").mean()\n",
    "smaller_groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Histogram of the overlay; emoji use for JB vs the emoji use for JT \n",
    "# smaller_groups.hist(by = \"username\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 2. Choose a test statistic (typically the difference in means between two categories\n",
    "# # Group(A) Average - Group(B) Average \n",
    "# # JB = A \n",
    "# # JT = B \n",
    "# # Negative values will tell me there is more evidence to support the null hypothesis \n",
    "# # Positive values will support the alternative hypothesis \n",
    "\n",
    "means_table = smaller_groups\n",
    "print(means_table)\n",
    "observed_difference = means_table[\"n_emojis\"][0] - means_table[\"n_emojis\"][1]\n",
    "observed_difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Choose a test statistic (typically the difference in means between two categories)\n",
    "\n",
    "## **What I want:**  We want to run a difference in means between the average number of emojis used inJB's IG posts vs JT's IG posts \n",
    "\n",
    "Which_Justin = Table.read_table('Which_Justin_120.csv')\n",
    "\n",
    "def difference_of_means(table, label, group_label):\n",
    "    \"\"\"Takes: name of table, column label of numerical variable,\n",
    "    column label of group-label variable\n",
    "    Returns: Difference of means of the two groups\"\"\"\n",
    "    \n",
    "    #table with the two relevant columns\n",
    "    reduced = table.select(label, group_label)  \n",
    "    \n",
    "    # table containing group means\n",
    "    means_table = reduced.group(group_label, np.average)\n",
    "    # array of group means\n",
    "    means = means_table.column(1)\n",
    "    \n",
    "    return means.item(1) - means.item(0)\n",
    "\n",
    "difference_of_means(Which_Justin, \"n_emojis\", \"username\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Shuffle the labels of the original sample, find your simulated test statistic, and repeat many times\n",
    "def one_simulated_difference(table, label, group_label):\n",
    "    \"\"\"Takes: name of table, column label of numerical variable,\n",
    "    column label of group-label variable\n",
    "    Returns: Difference of means of the two groups after shuffling labels\"\"\"\n",
    "    \n",
    "    # array of shuffled labels\n",
    "    shuffled_labels = table.sample(with_replacement = False).column(group_label)\n",
    "    \n",
    "    # table of numerical variable and shuffled labels\n",
    "    shuffled_table = table.select(label).with_column(\n",
    "        'Shuffled Label', shuffled_labels)\n",
    "    \n",
    "    return difference_of_means(shuffled_table, label, 'Shuffled Label')  \n",
    "\n",
    "one_simulated_difference(Which_Justin, \"n_emojis\", \"username\")\n",
    "\n",
    "differences = make_array()\n",
    "\n",
    "for i in np.arange(1000):\n",
    "    new_difference = one_simulated_difference(Which_Justin, \"n_emojis\", \"username\")\n",
    "    differences = np.append(differences, new_difference)\n",
    "\n",
    "# # 4. Find the value of the observed test statistic \n",
    "Table().with_column('Difference Between Group Means', differences).hist()\n",
    "print('Observed Difference:', observed_difference)\n",
    "\n",
    "plt.title('Prediction Under the Null Hypothesis');\n",
    "plt.plot([observed_difference, observed_difference], [0, .5], color='red', lw=2);\n",
    "\n",
    "# 5. Calculate the p-value based off your observed and simulated test statistics \n",
    "sum(differences <= observed_difference)/5000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Use the p-value and p-value cutoff to draw a conclusion about the null hypothesis\n",
    "Based on the histogram, our observed value appears close to the center of the spread of the histogram. What we got here appears to be what we would expect to see by chance.  With a P-Value of 0.072 that is greater than a default alpha level of 0.05, which means we fail to reject the null hypothesis.  We have evidence to support that the average number of emojis used in JB's IG posts is equal to the average number of emokis used in JT's IG posts. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.2.1** Construct a new table `Justin_Timberlake` containing only the 200 Instagram posted made by Justin Timberlake in the `Which_Justin` table. The `Justin_Timberlake` table should have an additional column `hashtags`. The `n_hashtags` column is already contained in the table, counting the number of hashtags in each Instagram post. The new column `hashtags` should be equal to `1` if the post has at least 1 hashtag and equal to 0 if the post has no hashtags. *(4 pts)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Justin_Timberlake = Which_Justin_df[Which_Justin_df[\"username\"] == \"justintimberlake\"]\n",
    "Justin_Timberlake[\"hashtags\"] = [1 if x >= 1 else 0 for x in Justin_Timberlake[\"n_hashtags\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "JT_1_hashtag = Justin_Timberlake[Justin_Timberlake[\"hashtags\"] == 1]\n",
    "JT_0_hashtag = Justin_Timberlake[Justin_Timberlake[\"hashtags\"] == 0]\n",
    "\n",
    "JT_0_hashtag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.2.2** Construct a 95% confidence interval to predict the average number of likes on Justin Timberlake's Instagram posts that contain at least one hashtag. *(6 pts)*\n",
    "\n",
    "**To receive full credit you should:**\n",
    "\n",
    "1. Take bootstrap samples from the original sample, compute the average number of likes, and repeat at least 1000 times\n",
    "\n",
    "2. Determine the upper and lower bounds of the 95% confidence interval\n",
    "\n",
    "3. Assign the bounds of the confidence interval to: lower_bound_222, upper_bound_222\n",
    "\n",
    "You may do this in as many lines as needed, and may add cells as well. You can (should) use functions that we have used in class, homework, labs, or from the text! You do **not** need to plot a histogram of the bootstrap statistics with the confidence interval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "JT_table_1_hashtags = Table.from_df(JT_1_hashtag, keep_index=False)\n",
    "#1. Take bootstrap samples from the original sample, compute the average number of likes, and repeat at least 1000 times\n",
    "our_sample = JT_table_1_hashtags.sample(100, with_replacement=False)\n",
    "our_sample_like_average = np.mean(our_sample.column('n_likes'))\n",
    "\n",
    "def one_bootstrap_mean():\n",
    "    single_sample = our_sample.sample()\n",
    "    return np.mean(single_sample.column('n_likes'))\n",
    "\n",
    "one_bootstrap_mean()\n",
    "\n",
    "bootstrap_means = make_array()\n",
    "\n",
    "for i in np.arange(1000):\n",
    "    new_mean = one_bootstrap_mean()\n",
    "    bootstrap_means = np.append(bootstrap_means, new_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lower_bound_222 = percentile(2.5, bootstrap_means)\n",
    "upper_bound_222 = percentile(97.5, bootstrap_means)\n",
    "\n",
    "lower_bound_222, upper_bound_222"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.2.3** Construct a 95% confidence interval to predict the average number of likes on Justin Timberlake's Instagram posts that contain **zero** hashtags. *(6 pts)*\n",
    "\n",
    "**To receive full credit you should:**\n",
    "\n",
    "1. Take bootstrap samples from the original sample, compute the average number of likes, and repeat at least 1000 times\n",
    "\n",
    "2. Determine the upper and lower bounds of the 95% confidence interval\n",
    "\n",
    "3. Assign the bounds of the confidence interval to: lower_bound_223, upper_bound_223\n",
    "\n",
    "You may do this in as many lines as needed, and may add cells as well. You can (should) use functions that we have used in class, homework, labs, or from the text! You do **not** need to plot a histogram of the bootstrap statistics with the confidence interval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "JT_table_0_hashtags = Table.from_df(JT_0_hashtag, keep_index=False)\n",
    "#1. Take bootstrap samples from the original sample, compute the average number of likes, and repeat at least 1000 times\n",
    "our_sample = JT_table_0_hashtags.sample(70, with_replacement=False)\n",
    "our_sample_like_average = np.mean(our_sample.column('n_likes'))\n",
    "\n",
    "def one_bootstrap_mean():\n",
    "    single_sample = our_sample.sample()\n",
    "    return np.mean(single_sample.column('n_likes'))\n",
    "\n",
    "one_bootstrap_mean()\n",
    "\n",
    "bootstrap_means = make_array()\n",
    "\n",
    "for i in np.arange(1000):\n",
    "    new_mean = one_bootstrap_mean()\n",
    "    bootstrap_means = np.append(bootstrap_means, new_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lower_bound_223 = percentile(2.5, bootstrap_means)\n",
    "upper_bound_223 = percentile(97.5, bootstrap_means)\n",
    "\n",
    "lower_bound_223, upper_bound_223"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.2.4** Do you have evidence to say that the average number of likes on Justin Timberlake's Instagram posts is different between posts with at least one hashtag versus the posts without a hashtag? Why or why not? Use your confidence intervals in the previous two questions to justify your answer. *(2 pts)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No, we do not have evidence ot say that the average number of likes on Justin Timberlake's IG posts are different between posts with at least one hashtag vs posts without a hashtag because the 95% confidence interval contains overlapping values and if the true population value falls in that overlapping value set, then there would be no difference between posts with at least one hashtag vs posts without a hashtag.  If the confidence intervals did not overlap, we would have evidence that there could be a difference between the groups. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.3** A recent study analyzing Instagram posts during the first quarter of 2021 found that 16.6% of all Instagram posts contained a video. For the `Which_Justin` table containing posts from all three Justins, is there evidence to suggest that these Justins post videos a different proportion of the time compared to other Instagram users (posting videos 16.6% of the time)? *(10 pts)*\n",
    "\n",
    "Perform a hypotheses test to test the above claim. **To receive full credit you should:**\n",
    "\n",
    "1. Choose and cite appropriate null and alternative hypotheses\n",
    "\n",
    "2. Choose an appropriate test statistic\n",
    "\n",
    "3. Find the value of the observed test statistic\n",
    "\n",
    "4. Assume the null hypothesis is true and sample from the theoretical population under the null hypothesis and obtain the simulated test statistic. Repeat this 1000 times.\n",
    "\n",
    "5. Plot your simulated test statistics in a histogram along with the observed test statistic\n",
    "\n",
    "6. Calculate the p-value based off of your observed and simulated test statistics\n",
    "\n",
    "7. Use the p-value to draw a conclusion and explain the conclusion using simple, non-technical language in the context of the problem with complete sentences\n",
    "\n",
    "You may do this in as many lines as needed, and may add cells as well. You can (should) use functions that we have used in class, homework, labs, or from the text!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smaller_JT = Which_Justin_df[[\"username\", \"is_video\"]]\n",
    "proportions_smaller = smaller_JT.groupby(\"username\").sum()/137\n",
    "proportions_smaller"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## JUSTIN BIEBER \n",
    "\n",
    "# 1. Choose and cite appropriate null and alternative hypotheses\n",
    "\n",
    "# Null Hypothesis: The proportion of videos posted by Justin Bieber on his IG is equal to the proportion of all IG posts containing videos \n",
    "# Alternative Hypothesis: The proportion of  videos posted by Justin Bieber on his IG is not equal \n",
    "\n",
    "model_proportions = make_array(proportions_smaller[\"is_video\"][0], .166)\n",
    "\n",
    "# 2. Choose an appropriate test statistic\n",
    "# We want a test for proportions \n",
    "\n",
    "def statistic(expected_prop, actual_prop):\n",
    "    return 100*abs(expected_prop - actual_prop)\n",
    "\n",
    "# 3. Find the value of the observed test statistic\n",
    "observed_statistic = statistic(0.5, 18/24)\n",
    "\n",
    "# 4. Assume the null hypothesis is true and sample from the theoretical population under the null hypothesis and obtain the simulated test statistic. Repeat this 1000 times.\n",
    "num_simulations = 1000\n",
    "\n",
    "def simulation_and_statistic(model_proportions, expected_proportion_correct):\n",
    "       \n",
    "    simulation_proportion_correct = sample_proportions(24, model_proportions)\n",
    "    one_statistic = statistic(simulation_proportion_correct.item(0), expected_proportion_correct)\n",
    "    \n",
    "    return one_statistic\n",
    "\n",
    "simulated_statistics = make_array()\n",
    "\n",
    "for i in np.arange(num_simulations):\n",
    "    simulated_statistic = simulation_and_statistic(model_proportions, 0.5)\n",
    "    simulated_statistics = np.append(simulated_statistics, simulated_statistic)\n",
    "\n",
    "\n",
    "# 5. Plot your simulated test statistics in a histogram along with the observed test statistic\n",
    "Table().with_column('Simulated Statistics', simulated_statistics).hist(bins = np.arange(0, 50, 4.16))\n",
    "plt.plot([observed_statistic, observed_statistic], [0, .08], color='red', lw=2);\n",
    "\n",
    "# 6. Calculate the p-value based off of your observed and simulated test statistics\n",
    "print(\"p-value:  \", sum(simulated_statistics >= observed_statistic)/num_simulations)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Use the p-value to draw a conclusion and explain the conclusion using simple, non-technical language in the context of the problem with complete sentences\n",
    "\n",
    "Based on the histogram, our observed value appeares close to the center of the spread of the histrogram.  What we got here appears to be what we would expect to see by chance.  With a p-value of 0.626 that is greater than the default alpha level of 0.05, this means we fail to reject the null hypothesis.  We have evidence to support that the proportion of videos posted by Justin Bieber on his IG is equal to the proportion of all IG posts containing videos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## JUSTIN CANADA \n",
    "\n",
    "# 1. Choose and cite appropriate null and alternative hypotheses\n",
    "\n",
    "# Null Hypothesis: The proportion of videos posted by JUSTIN CANADA  on his IG is equal to the proportion of all IG posts containing videos \n",
    "# Alternative Hypothesis: The proportion of  videos posted by JUSTIN CANADA  on his IG is not equal \n",
    "\n",
    "model_proportions = make_array(proportions_smaller[\"is_video\"][1], .166)\n",
    "\n",
    "# 2. Choose an appropriate test statistic\n",
    "# We want a test for proportions \n",
    "\n",
    "def statistic(expected_prop, actual_prop):\n",
    "    return 100*abs(expected_prop - actual_prop)\n",
    "\n",
    "# 3. Find the value of the observed test statistic\n",
    "observed_statistic = statistic(0.5, 18/24)\n",
    "\n",
    "# 4. Assume the null hypothesis is true and sample from the theoretical population under the null hypothesis and obtain the simulated test statistic. Repeat this 1000 times.\n",
    "num_simulations = 1000\n",
    "\n",
    "def simulation_and_statistic(model_proportions, expected_proportion_correct):\n",
    "       \n",
    "    simulation_proportion_correct = sample_proportions(24, model_proportions)\n",
    "    one_statistic = statistic(simulation_proportion_correct.item(0), expected_proportion_correct)\n",
    "    \n",
    "    return one_statistic\n",
    "\n",
    "simulated_statistics = make_array()\n",
    "\n",
    "for i in np.arange(num_simulations):\n",
    "    simulated_statistic = simulation_and_statistic(model_proportions, 0.5)\n",
    "    simulated_statistics = np.append(simulated_statistics, simulated_statistic)\n",
    "\n",
    "\n",
    "# 5. Plot your simulated test statistics in a histogram along with the observed test statistic\n",
    "Table().with_column('Simulated Statistics', simulated_statistics).hist(bins = np.arange(0, 50, 4.16))\n",
    "plt.plot([observed_statistic, observed_statistic], [0, .08], color='red', lw=2);\n",
    "\n",
    "# 6. Calculate the p-value based off of your observed and simulated test statistics\n",
    "print(\"p-value:  \", sum(simulated_statistics >= observed_statistic)/num_simulations)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Use the p-value to draw a conclusion and explain the conclusion using simple, non-technical language in the context of the problem with complete sentences\n",
    "\n",
    "Based on the histogram, our observed value appeares close to the center of the spread of the histrogram.  What we got here appears to be what we would expect to see by chance.  With a p-value of 0.827 that is greater than the default alpha level of 0.05, this means we fail to reject the null hypothesis.  We have evidence to support that the proportion of videos posted by JUSTIN CANADA  on his IG is equal to the proportion of all IG posts containing videos. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## JUSTIN TIMBERLAKE \n",
    "\n",
    "# 1. Choose and cite appropriate null and alternative hypotheses\n",
    "\n",
    "# Null Hypothesis: The proportion of videos posted by JUSTIN TIMBERLAKE  on his IG is equal to the proportion of all IG posts containing videos \n",
    "# Alternative Hypothesis: The proportion of  videos posted by JUSTIN TIMBERLAKE  on his IG is not equal \n",
    "\n",
    "model_proportions = make_array(proportions_smaller[\"is_video\"][2], .166)\n",
    "\n",
    "# 2. Choose an appropriate test statistic\n",
    "# We want a test for proportions \n",
    "\n",
    "def statistic(expected_prop, actual_prop):\n",
    "    return 100*abs(expected_prop - actual_prop)\n",
    "\n",
    "# 3. Find the value of the observed test statistic\n",
    "observed_statistic = statistic(0.5, 18/24)\n",
    "\n",
    "# 4. Assume the null hypothesis is true and sample from the theoretical population under the null hypothesis and obtain the simulated test statistic. Repeat this 1000 times.\n",
    "num_simulations = 1000\n",
    "\n",
    "def simulation_and_statistic(model_proportions, expected_proportion_correct):\n",
    "       \n",
    "    simulation_proportion_correct = sample_proportions(24, model_proportions)\n",
    "    one_statistic = statistic(simulation_proportion_correct.item(0), expected_proportion_correct)\n",
    "    \n",
    "    return one_statistic\n",
    "\n",
    "simulated_statistics = make_array()\n",
    "\n",
    "for i in np.arange(num_simulations):\n",
    "    simulated_statistic = simulation_and_statistic(model_proportions, 0.5)\n",
    "    simulated_statistics = np.append(simulated_statistics, simulated_statistic)\n",
    "\n",
    "\n",
    "# 5. Plot your simulated test statistics in a histogram along with the observed test statistic\n",
    "Table().with_column('Simulated Statistics', simulated_statistics).hist(bins = np.arange(0, 50, 4.16))\n",
    "plt.plot([observed_statistic, observed_statistic], [0, .08], color='red', lw=2);\n",
    "\n",
    "# 6. Calculate the p-value based off of your observed and simulated test statistics\n",
    "print(\"p-value:  \", sum(simulated_statistics >= observed_statistic)/num_simulations)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Use the p-value to draw a conclusion and explain the conclusion using simple, non-technical language in the context of the problem with complete sentences\n",
    "\n",
    "Based on the histogram, our observed value appeares close to the center of the spread of the histrogram.  What we got here appears to be what we would expect to see by chance.  With a p-value of 0.053 that is only slightly greater than the default alpha level of 0.05, this means we fail to reject the null hypothesis.  The proportion of videos posted by JUSTIN TIMBERLAKE  on his IG is equal to the proportion of all IG posts containing videos.\n",
    "\n",
    "Despite barely reaching the cut off for a 0.05 alpha level, I would feel more comfortable running this again a different alpha level to see if we get the same result.  This barely meets the requirements to fail to reject the null hypothesis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PythonData",
   "language": "python",
   "name": "pythondata"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
