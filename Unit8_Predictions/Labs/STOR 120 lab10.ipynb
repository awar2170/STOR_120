{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 10: Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell to set up the notebook, but please don't change it.\n",
    "import numpy as np\n",
    "import math\n",
    "from datascience import *\n",
    "\n",
    "# These lines set up the plotting functionality and formatting.\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plots\n",
    "plots.style.use('fivethirtyeight')\n",
    "import warnings\n",
    "warnings.simplefilter(action=\"ignore\", category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. The Dataset\n",
    "\n",
    "In this lab, we are exploring movie screenplays. In particular, we have compiled a list of 5,000 words (including stemmed words) that occur in conversations between movie characters. For each movie, our dataset tells us the frequency with which each of these words occurs in certain conversations in its screenplay. All words have been converted to lowercase.\n",
    "\n",
    "Run the cell below to read the `movies` table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies = Table.read_table('movies.csv')\n",
    "movies.where(\"Title\", \"wild wild west\").select(0, 1, 2, 3, 4, 14, 49, 1042, 4004)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above cell prints a few columns of the row for the comedy movie *Wild Wild West*.  The movie contains 3446 words. The word \"it\" appears 74 times, as it makes up  $\\frac{74}{3446} \\approx 0.021364$ of the words in the movie. The word \"england\" doesn't appear at all.\n",
    "This numerical representation of a body of text, one that describes only the frequencies of individual words, is called a bag-of-words representation. A lot of information is discarded in this representation: the order of the words, the context of each word, who said what, the cast of characters and actors, etc. However, a bag-of-words representation is often used for machine learning applications as a reasonable starting point, because a great deal of information is also retained and expressed in a convenient and compact format."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All movie titles are unique. The `row_for_title` function provides fast access to the one row for each title. \n",
    "\n",
    "*Note: All movies in our dataset have their titles lower-cased.* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "title_index = movies.index_by('Title')\n",
    "def row_for_title(title):\n",
    "    \"\"\"Return the row for a title, similar to the following expression (but faster)\n",
    "    \n",
    "    movies.where('Title', title).row(0)\n",
    "    \"\"\"\n",
    "    return title_index.get(title)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, the fastest way to find the frequency of \"none\" in the movie *The Terminator* is to access the `'none'` item from its row. Check the original table to see if this worked for you!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row_for_title('the terminator').item('none') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 1.1\n",
    "Set `expected_row_sum` to the number that you __expect__ will result from summing all proportions in each row, excluding the first five columns.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q1_1\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set row_sum to a number that's the (approximate) sum of each row of word proportions.\n",
    "expected_row_sum = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dataset was extracted from [a dataset from Cornell University](http://www.cs.cornell.edu/~cristian/Cornell_Movie-Dialogs_Corpus.html). After transforming the dataset (e.g., converting the words to lowercase, removing the naughty words, and converting the counts to frequencies), we created this new dataset containing the frequency of 5000 common words in each movie."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 2. Relationships Between Pairs of Words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this section we will look at the relationship between the proportion of the word `her` in screenplays versus the word `she`. We would like to use linear regression to make predictions about this relationship, but that won't work well if the data aren't roughly linearly related. To check that, we should look at the data. Run the cell below to construct a new table `she_her` that contains only the proportions of the words `she` and `her` in the screenplays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "she_her = movies.select(\"she\", \"her\")\n",
    "she_her"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.1.** Make a scatter plot of the data.  It's conventional to put the column we want to predict on the vertical axis and the other column on the horizontal axis. Lets's say we want to use the proportions of `she` to predict the proportions of `her`\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q2_1\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.2.** Are the proportions of `she` and `her` in the screenplays roughly linearly related based on the scatter plot above?\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q2_2\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Write your answer here, replacing this text.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're going to continue with the assumption that they are linearly related, so it's reasonable to use linear regression to analyze this data.\n",
    "\n",
    "We'd next like to plot the data in standard units. If you don't remember the definition of standard units, textbook section [14.2](https://www.inferentialthinking.com/chapters/14/2/Variability.html#standard-units) might help!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.3.** Compute the mean and standard deviation for the proportions of `she` and `her` in the screenplays.  **Then** create a table called `she_her_standard` containing the proportions of `she` and `her` in the screenplays in standard units.  The columns should be named `she (standard units)` and `her (standard units)`.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q2_3\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "for_assignment_type": "solution"
   },
   "outputs": [],
   "source": [
    "she_mean = ...\n",
    "she_std = ...\n",
    "her_mean = ...\n",
    "her_std = ...\n",
    "\n",
    "she_her_standard = Table().with_columns(\n",
    "    \"she (standard units)\", ...,\n",
    "    \"her (standard units)\", ...\n",
    ")\n",
    "\n",
    "she_her_standard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.4.** Plot the data again, but this time in standard units.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q2_4\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You'll notice that this plot looks the same as the last one!  However, the data and axes are scaled differently.  So it's important to read the ticks on the axes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.5.** Which would you guess best describes the correlation between the proportions of `she` and `her` in this dataset?\n",
    "\n",
    "1. correlation is positive (but not close to zero)\n",
    "2. correlation is close to zero\n",
    "3. correlation is negative (but not close to zero)\n",
    "\n",
    "Assign `correlation` to the number corresponding to your guess.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q2_5\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.6.** Compute the correlation `r`.  \n",
    "\n",
    "*Hint:* Use `she_her_standard`.  Section [15.1](https://www.inferentialthinking.com/chapters/15/1/Correlation.html#calculating-r) explains how to do this.\n",
    "\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q2_6\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = ...\n",
    "r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. The regression line\n",
    "Correlation is the **slope of the regression line when the data are put in standard units**.\n",
    "\n",
    "The next cell plots the regression line in standard units:\n",
    "\n",
    "$$\\text{her proportion in standard units} = r \\times \\text{she proportions in standard units}.$$\n",
    "\n",
    "Then, it plots the data in standard units again, for comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_line(slope=0, intercept=0, x=make_array(-1.5, 6), color='r'):\n",
    "    y = x*slope + intercept\n",
    "    plots.plot(x, y, color=color)\n",
    "\n",
    "she_her_standard.scatter('she (standard units)', 'her (standard units)')\n",
    "draw_line(slope = r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How would you take a point in standard units and convert it back to original units?  We'd have to \"stretch\" its horizontal position by `she_std` and its vertical position by `her_std`. That means the same thing would happen to the slope of the line.\n",
    "\n",
    "Stretching a line horizontally makes it less steep, so we divide the slope by the stretching factor.  Stretching a line vertically makes it more steep, so we multiply the slope by the stretching factor.\n",
    "\n",
    "**Question 3.1.** Calculate the slope of the regression line in original units, and assign it to `slope`.\n",
    "\n",
    "(If the \"stretching\" explanation is unintuitive, consult section [15.2](https://www.inferentialthinking.com/chapters/15/2/Regression_Line.html#the-equation-of-the-regression-line) in the textbook.)\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q3_1\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slope = ...\n",
    "slope"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We know that the regression line passes through the point `(she_mean, her_mean)`.  You might recall from high-school algebra that the equation for the line is therefore:\n",
    "\n",
    "$$\\text{her proportion} - \\verb|her_mean| = \\texttt{slope} \\times (\\text{she proportion} - \\verb|she_mean|)$$\n",
    "\n",
    "The rearranged equation becomes:\n",
    "\n",
    "$$\\text{her proportion} = \\texttt{slope} \\times \\text{she proportion} + (- \\texttt{slope} \\times \\verb|she_mean| + \\verb|her_mean|)$$\n",
    "\n",
    "\n",
    "**Question 3.2.** Calculate the intercept in original units and assign it to `intercept`.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q3_2\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intercept = ...\n",
    "intercept"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Investigating the regression line\n",
    "The slope and intercept tell you exactly what the regression line looks like. To predict the proportion of the words in a screenplay that are `her` , multiply the proportion of the words in a screenplay that are `she` by `slope` and then add `intercept`.\n",
    "\n",
    "**Question 3.1.** Compute the the proportion of the words in a screenplay that are `her` for a screenplay with `she` occurring for 0.005 proportion of the words and for a screenplay with `she` occurring for 0.015 proportion of the words\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q3_1\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "her_prop_for_she005 = ...\n",
    "her_prop_for_she015 = ...\n",
    "\n",
    "# Here is a helper function to print out your predictions.\n",
    "# Don't modify the code below.\n",
    "def print_prediction(she, predicted_her):\n",
    "    print(\"For a screenplay with 'she' occurring for\", she,\n",
    "          \"proportion of the words, we predict that 'her' would occur in the screenplay\", predicted_her,\n",
    "          \"proportion of the words.\")\n",
    "\n",
    "print_prediction(0.005, her_prop_for_she005)\n",
    "print_prediction(0.015, her_prop_for_she015)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next cell plots the line that goes between those two points, which is (a segment of) the regression line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "she_her.scatter('she', 'her')\n",
    "draw_line(\n",
    "    slope = slope,\n",
    "    intercept = intercept,\n",
    "    x = make_array(0.005, 0.0015)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3.2.** Make predictions for the proportion of words that are `her` for each screenplay in the `she_her` table.  (Of course, we know exactly what the proportions are! We are doing this so we can see how accurate our predictions are.)  Put these numbers into a column in a new table called `her_predictions` that also includes the columns of the `she_her` table.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q3_2\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "her_predictions = ...\n",
    "her_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3.3.** How close were we?  Compute the *residual* for each screenplay in the dataset.  The residual is the actual proportion of the words that are `her` minus the predicted proportion of the words that are `her`.  Add the residuals to `her_predictions` as a new column called `residual` and name the resulting table `her_residuals`.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q3_3\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "her_residuals = ...\n",
    "her_residuals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is a plot of the residuals you computed.  Each point corresponds to one screenplay.  It shows how much our prediction over- or under-estimated the proportion of `her` words in the screenplay."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "her_residuals.scatter(\"she\", \"residual\", color=\"r\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. More Words for Multiple Regression\n",
    "\n",
    "#### Question 4.1\n",
    "Choose a new word in the dataset that you think could be used to predict the proportion of the word `her` in a screenplay. The new word should have a correlation of greater than 0.05 or less than -0.0.5 with `her`. The code to plot the scatter plot and line of best fit is given for you, you just need to calculate the correct values for `r_her_new_word`, `slope_her_new_word` and `intercept_her_new_word`.\n",
    "\n",
    "*Hint: It's easier to think of words with a positive correlation, i.e. words that are often mentioned together*.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q4_1\n",
    "manual: true\n",
    "image: true\n",
    "-->\n",
    "<!-- EXPORT TO PDF -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "export_pdf": true
   },
   "outputs": [],
   "source": [
    "new_word = ...\n",
    "\n",
    "# This array should make your code cleaner!\n",
    "arr_new_word = movies.column(new_word)\n",
    "\n",
    "new_word_su = ...\n",
    "\n",
    "r_her_new_word = ...\n",
    "\n",
    "slope_her_new_word = ...\n",
    "intercept_her_new_word = ...\n",
    "\n",
    "# DON'T CHANGE THESE LINES OF CODE\n",
    "movies.scatter(new_word, 'her')\n",
    "max_x = max(movies.column(new_word))\n",
    "print('Correlation:', r_her_new_word)\n",
    "plots.plot([0, max_x * 1.3], [intercept_her_new_word, intercept_her_new_word + slope_her_new_word * (max_x*1.3)], color='gold');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In class we saw that the best fit regression line used to predict y with x minimized the root mean squared error (rmse). \n",
    "\n",
    "$$\n",
    "rmse ~=~ \\sqrt{mean{(y - y_{estimate})}^2}\n",
    "$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 4.2\n",
    "Define the function below to calculate the root mean squared error for a regression line that uses the proportion of `new_word` as predictor for the proportion of `her`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def her_new_word_rmse(any_slope, any_intercept):\n",
    "\n",
    "    ...\n",
    "\n",
    "    return ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the cells below to see that the minimize function will (most likely) output the same values for the slope and intercept that you calculated in question 3.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "minimize(her_new_word_rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slope_her_new_word, intercept_her_new_word"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This method of using the minimize function to find the minimum root mean squared value for a function can be extended to nonlinear models as well as to models with multiple predictors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 4.2 \n",
    "\n",
    "Use the proportions of your `new_word` and `she` to construct a multiple regression model to predict the proportion of the words in the script that are `her`.\n",
    "\n",
    "\n",
    "$$\n",
    "her_{estimate} ~=~ a*newword + b*she + c\n",
    "$$\n",
    "\n",
    "for constants $a$, $b$, and $c$\n",
    "\n",
    "Define the function below to calculate the root mean squared error for a regression line that has the proportions of these words as predictors for the proportion of `her` in a screenplay."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def she_new_her_rmse(a, b, c):\n",
    "\n",
    "    ...\n",
    "\n",
    "    return ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 4.3\n",
    "\n",
    "Use the minimize function to find the coefficients  $a$, $b$, and $c$ that result in the minimal root mean squared error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 4.4\n",
    "\n",
    "For the movie The Terminator, what proportion of the words in the script does your model predict will be `her` using the proportion of your `new_word` and `she` in a screenplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You have finished lab 10! We'll use this data again in lab 11 in an attempt to classify the genre of movies."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
