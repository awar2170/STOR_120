{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datascience import *\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plots\n",
    "plots.style.use('fivethirtyeight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standard_units(x):\n",
    "    return (x - np.mean(x))/np.std(x)\n",
    "\n",
    "def distance(point1, point2):\n",
    "    \"\"\"Returns the distance between point1 and point2\n",
    "    where each argument is an array \n",
    "    consisting of the coordinates of the point\"\"\"\n",
    "    return np.sqrt(np.sum((point1 - point2)**2))\n",
    "\n",
    "def all_distances(training, new_point):\n",
    "    \"\"\"Returns an array of distances\n",
    "    between each point in the training set\n",
    "    and the new point (which is a row of attributes)\"\"\"\n",
    "    attributes = training.drop('Class')\n",
    "    def distance_from_point(row):\n",
    "        return distance(np.array(list(new_point)), np.array(list(row)))\n",
    "    return attributes.apply(distance_from_point)\n",
    "\n",
    "def table_with_distances(training, new_point):\n",
    "    \"\"\"Augments the training table \n",
    "    with a column of distances from new_point\"\"\"\n",
    "    return training.with_column('Distance', all_distances(training, new_point))\n",
    "\n",
    "def closest(training, new_point, k):\n",
    "    \"\"\"Returns a table of the k rows of the augmented table\n",
    "    corresponding to the k smallest distances\"\"\"\n",
    "    with_dists = table_with_distances(training, new_point)\n",
    "    sorted_by_distance = with_dists.sort('Distance')\n",
    "    topk = sorted_by_distance.take(np.arange(k))\n",
    "    return topk\n",
    "\n",
    "def majority(topkclasses):\n",
    "    ones = topkclasses.where('Class', are.equal_to(1)).num_rows\n",
    "    zeros = topkclasses.where('Class', are.equal_to(0)).num_rows\n",
    "    if ones > zeros:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def classify(training, new_point, k):\n",
    "    closestk = closest(training, new_point, k)\n",
    "    topkclasses = closestk.select('Class')\n",
    "    return majority(topkclasses)\n",
    "\n",
    "def evaluate_accuracy(training, test, k):\n",
    "    \"\"\"Return the proportion of correctly classified examples \n",
    "    in the test set\"\"\"\n",
    "    test_attributes = test.drop('Class')\n",
    "    num_correct = 0\n",
    "    for i in np.arange(test.num_rows):\n",
    "        c = classify(training, test_attributes.row(i), k)\n",
    "        num_correct = num_correct + (c == test.column('Class').item(i))\n",
    "    return num_correct / test.num_rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Counterfeit Currency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "banknotes = Table.read_table('banknote.csv')\n",
    "banknotes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "banknotes.group('Class')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standardize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize data\n",
    "\n",
    "banknotes_SU = Table().with_columns(\n",
    "    'WaveletVar SU', standard_units(banknotes.column('WaveletVar')),\n",
    "    'WaveletSkew SU', standard_units(banknotes.column('WaveletSkew')),\n",
    "    'WaveletCurt SU', standard_units(banknotes.column('WaveletCurt')),\n",
    "    'Class', banknotes.column('Class'))\n",
    "\n",
    "banknotes_SU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split data into training and testing tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "banknotes.num_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 70%/30% for Training/Testing \n",
    "\n",
    "banknotes.num_rows * 0.70"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffled_banknotes_SU = banknotes_SU.sample(with_replacement=False) \n",
    "banknotes_SU_train = shuffled_banknotes_SU.take(np.arange(960))\n",
    "banknotes_SU_test  = shuffled_banknotes_SU.take(np.arange(960, 1372))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "banknotes_SU_test.group('Class')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classify data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attributes = banknotes_SU_test.drop('Class')\n",
    "\n",
    "classify(banknotes_SU_train, attributes.row(7), 9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How to choose K? That's complicated..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Determine the accuracy of the Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_accuracy(banknotes_SU_train, banknotes_SU_test, 9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This accuracy will depend on the randomly selected training and testing datasets. Let's assume that the accuracy is 99%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### If we test a random bill and classify it as counterfeit, what is the probability that it is _actually_ counterfeit?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "P(counterfeit) = 0.0001    \n",
    "P(Not counterfeit) = 0.9999\n",
    "\n",
    "__Assume that our accuracy if for both detecting counterfeit and non counterfeit bills__\n",
    "\n",
    "P(test+ | counterfeit) = 0.99    \n",
    "P(test- | counterfeit) = 0.01    \n",
    "\n",
    "P(test+ | not counterfeit) = 0.01    \n",
    "P(test- | counterfeit) = 0.99   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(0.0001 * 0.99) / ((0.0001 * 0.99) + (0.9999 * 0.01)) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
