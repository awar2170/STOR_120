{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 11: Movie Classification\n",
    "In this lab you will build a classifier that guesses whether a movie is a comedy or a thriller, using only the number of times words appear in the movies's screenplay. By the end of the lab, you should know how to:\n",
    "\n",
    "1. Build a k-nearest-neighbors classifier.\n",
    "2. Test a classifier on data.\n",
    "\n",
    "To get started, run the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell to set up the notebook, but please don't change it.\n",
    "import numpy as np\n",
    "import math\n",
    "from datascience import *\n",
    "\n",
    "# These lines set up the plotting functionality and formatting.\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plots\n",
    "plots.style.use('fivethirtyeight')\n",
    "import warnings\n",
    "warnings.simplefilter(action=\"ignore\", category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. The Dataset (Again)\n",
    "\n",
    "In this lab we will again explore movie screenplays. We will be trying to predict each movie's genre from the text of its screenplay. In particular, we have compiled a list of 5,000 words that occur in conversations between movie characters. For each movie, our dataset tells us the frequency with which each of these words occurs in certain conversations in its screenplay. All words have been converted to lowercase.\n",
    "\n",
    "Run the cell below to read the `movies` table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies = Table.read_table('movies.csv')\n",
    "movies.where(\"Title\", \"wild wild west\").select(0, 1, 2, 3, 4, 14, 49, 1042, 4004)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above cell prints a few columns of the row for the comedy movie *Wild Wild West*.  The movie contains 3446 words. The word \"it\" appears 74 times, as it makes up  $\\frac{74}{3446} \\approx 0.021364$ of the words in the movie. The word \"england\" doesn't appear at all.\n",
    "This numerical representation of a body of text, one that describes only the frequencies of individual words, is called a bag-of-words representation. A lot of information is discarded in this representation: the order of the words, the context of each word, who said what, the cast of characters and actors, etc. However, a bag-of-words representation is often used for machine learning applications as a reasonable starting point, because a great deal of information is also retained and expressed in a convenient and compact format. In this project, we will investigate whether this representation is sufficient to build an accurate genre classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All movie titles are unique. The `row_for_title` function provides fast access to the one row for each title. \n",
    "\n",
    "*Note: All movies in our dataset have their titles lower-cased.* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_index = movies.index_by('Title')\n",
    "def row_for_title(title):\n",
    "    \"\"\"Return the row for a title, similar to the following expression (but faster)\n",
    "    \n",
    "    movies.where('Title', title).row(0)\n",
    "    \"\"\"\n",
    "    return title_index.get(title)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, the fastest way to find the frequency of \"none\" in the movie *The Terminator* is to access the `'none'` item from its row. Check the original table to see if this worked for you!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row_for_title('the terminator').item('none') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1. Splitting the dataset\n",
    "We're going to use our `movies` dataset for two purposes.\n",
    "\n",
    "1. First, we want to *train* movie genre classifiers.\n",
    "2. Second, we want to *test* the performance of our classifiers.\n",
    "\n",
    "Hence, we need two different datasets: *training* and *test*.\n",
    "\n",
    "The purpose of a classifier is to classify unseen data that is similar to the training data. Therefore, we must ensure that there are no movies that appear in both sets. We do so by splitting the dataset randomly. The dataset has already been permuted randomly, so it's easy to split.  We just take the top for training and the rest for test. \n",
    "\n",
    "Run the code below (without changing it) to separate the datasets into two tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we have defined the proportion of our data\n",
    "# that we want to designate for training as 17/20ths\n",
    "# of our total dataset.  3/20ths of the data is\n",
    "# reserved for testing.\n",
    "\n",
    "training_proportion = 17/20\n",
    "\n",
    "num_movies = movies.num_rows\n",
    "num_train = int(num_movies * training_proportion)\n",
    "num_test = num_movies - num_train\n",
    "\n",
    "train_movies = movies.take(np.arange(num_train))\n",
    "test_movies = movies.take(np.arange(num_train, num_movies))\n",
    "\n",
    "print(\"Training: \",   train_movies.num_rows, \";\",\n",
    "      \"Test: \",       test_movies.num_rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. K-Nearest Neighbors - A Guided Example\n",
    "\n",
    "K-Nearest Neighbors (k-NN) is a classification algorithm.  Given some numerical *attributes* (also called *features*) of an unseen example, it decides whether that example belongs to one or the other of two categories based on its similarity to previously seen examples. Predicting the category of an example is called *labeling*, and the predicted category is also called a *label*.\n",
    "\n",
    "An attribute (feature) we have about each movie is *the proportion of times a particular word appears in the movies*, and the labels are two movie genres: comedy and thriller.  The algorithm requires many previously seen examples for which both the attributes and labels are known: that's the `train_movies` table.\n",
    "\n",
    "To build understanding, we're going to visualize the algorithm instead of just describing it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 2.1. Classifying a movie\n",
    "\n",
    "In k-NN, we classify a movie by finding the `k` movies in the *training set* that are most similar according to the features we choose. We call those movies with similar features the *nearest neighbors*.  The k-NN algorithm assigns the movie to the most common category among its `k` nearest neighbors.\n",
    "\n",
    "Let's limit ourselves to just 2 features for now, so we can plot each movie.  The features we will use are the proportions of the words \"paid\" and \"rent\" in the movie.  Taking the movie *Fast Times at Ridgemont High* (in the test set), 0.0001915341 of its words are \"paid\" and 0.0001915341 are \"rent\". This movie appears in the test set, so let's imagine that we don't yet know its genre.\n",
    "\n",
    "First, we need to make our notion of similarity more precise.  We will say that the *distance* between two movies is the straight-line distance between them when we plot their features in a scatter diagram. \n",
    "\n",
    "This distance is called the Euclidean (\"yoo-KLID-ee-un\") distance, whose formula is: \n",
    "&nbsp;\n",
    "\n",
    "<center> $\\sqrt{(x_1 - x_2)^2 + (y_1 - y_2)^2}$. </center>\n",
    "&nbsp;\n",
    "\n",
    "For example, in the movie *Ghostbusters* (in the training set), 0.0002191060 of all the words in the movie are \"paid\" and 0 are \"rent\".  Its distance from *Fast Times at Ridgemont High* on this 2-word feature set is: \n",
    "&nbsp;\n",
    "\n",
    "<center> $\\sqrt{(0.0001915341 - 0.0002191060)^2 + (0.0001915341 - 0)^2} \\approx 0.0001935084$. </center> \n",
    "&nbsp;\n",
    "\n",
    "A third movie, *Point Break* (in the training set), is 0 \"paid\" and 0.0002754820 \"rent\".\n",
    "\n",
    "The function below creates a plot to display the \"paid\" and \"rent\" features of a test movie and some training movies. As you can see in the result, *Fast Times at Ridgemont High* is more similar to *Ghostbusters* than to the *Point Break* based on these features, which makes sense as both movies are comedy movies, while *Point Break* is a thriller.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just run this cell.\n",
    "def plot_with_two_features(test_movie, training_movies, x_feature, y_feature):\n",
    "    \"\"\"Plot a test movie and training movies using two features.\"\"\"\n",
    "    test_row = row_for_title(test_movie)\n",
    "    distances = Table().with_columns(\n",
    "            x_feature, [test_row.item(x_feature)],\n",
    "            y_feature, [test_row.item(y_feature)],\n",
    "            'Color',   ['unknown'],\n",
    "            'Title',   [test_movie]\n",
    "        )\n",
    "    for movie in training_movies:\n",
    "        row = row_for_title(movie)\n",
    "        distances.append([row.item(x_feature), row.item(y_feature), row.item('Genre'), movie])\n",
    "    distances.scatter(x_feature, y_feature, group='Color', labels='Title', s=30)\n",
    "    \n",
    "training = [\"ghostbusters\", \"point break\"] \n",
    "plot_with_two_features(\"fast times at ridgemont high\", training, \"paid\", \"rent\")\n",
    "plots.axis([-0.0001, 0.0003, -0.0001, 0.0004]);\n",
    "plots.xticks(rotation=90);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 2.1.1\n",
    "\n",
    "Compute the Euclidean distance (defined in the section above) between the two movies, *Fast Times at Ridgemont High* and *Point Break*, using the `paid` and `rent` features only.  Assign it the name `one_distance`.\n",
    "\n",
    "**Note:** If you have a row, you can use `item` to get a value from a column by its name.  For example, if `r` is a row, then `r.item(\"Genre\")` is the value in column `\"Genre\"` in row `r`.\n",
    "\n",
    "*Hint*: Remember the function `row_for_title`, redefined for you below.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q2_1_1\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_index = movies.index_by('Title')\n",
    "fast_times = row_for_title('fast times at ridgemont high') \n",
    "point_break = row_for_title(\"point break\") \n",
    "\n",
    "one_distance = ...\n",
    "one_distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, we've added a third training movie, *The Abyss*. Before, the point closest to *Fast Times at Ridgemont High* was *Ghostbusters*, a comedy movie. However, now the closest point is *The Abyss*, a thriller movie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training = [\"ghostbusters\", \"point break\", \"the abyss\"] \n",
    "plot_with_two_features(\"fast times at ridgemont high\", training, \"paid\", \"rent\") \n",
    "plots.axis([-0.0001, 0.00035, -0.0001, 0.0004]);\n",
    "plots.xticks(rotation=90);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 2.1.2\n",
    "Complete the function `distance_two_features` that computes the Euclidean distance between any two movies, using two features. The last two lines call your function to show that *Fast Times at Ridgemont High* is closer to *The Abyss* than it is to *Ghostbusters*. \n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q2_1_2\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance_two_features(title0, title1, x_feature, y_feature):\n",
    "    \"\"\"Compute the distance between two movies with titles title0 and title1\n",
    "    \n",
    "    Only the features named x_feature and y_feature are used when computing the distance.\n",
    "    \"\"\"\n",
    "    row0 = ...\n",
    "    row1 = ...\n",
    "    ...\n",
    "\n",
    "for movie in make_array(\"ghostbusters\", \"the abyss\"):\n",
    "    movie_distance = distance_two_features(movie, \"fast times at ridgemont high\", \"paid\", \"rent\")\n",
    "    print(movie, 'distance:\\t', movie_distance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 2.1.3\n",
    "Define the function `distance_from_fast_times` so that it works as described in its documentation.\n",
    "\n",
    "**Note:** Your solution should not use arithmetic operations directly. Instead, it should make use of existing functionality above!\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q2_1_3\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance_from_fast_times(title):\n",
    "    \"\"\"The distance between the given movie and \"fast times at ridgemont high\", \n",
    "    based on the features \"paid\" and \"rent\".\n",
    "    \n",
    "    This function takes a single argument:\n",
    "      title: A string, the name of a movie.\n",
    "    \"\"\"\n",
    "    \n",
    "    ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 2.1.4\n",
    "\n",
    "Using the features `\"paid\"` and `\"rent\"`, what are the names and genres of the 5 movies in the **training set** closest to *Fast Times at Ridgemont High*?  To answer this question, make a table named `close_movies` containing those 5 movies with columns `\"Title\"`, `\"Genre\"`, `\"paid\"`, and `\"rent\"`, as well as a column called `\"distance from fast times\"` that contains the distance from *Fast Times at Ridgemont High*.  The table should be **sorted in ascending order by `distance from fast times`**.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q2_1_4\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "for_assignment_type": "solution"
   },
   "outputs": [],
   "source": [
    "\n",
    "# The staff solution took multiple lines.\n",
    "...\n",
    "close_movies = ...\n",
    "close_movies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2.1.5\n",
    "Next, we'll classify *Fast Times at Ridgemont High* based on the genres of the closest movies. \n",
    "\n",
    "To do so, define the function `most_common` so that it works as described in its documentation below.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q2_1_5\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def most_common(label, table):\n",
    "    \"\"\"The most common element in a column of a table.\n",
    "    \n",
    "    This function takes two arguments:\n",
    "      label: The label of a column, a string.\n",
    "      table: A table.\n",
    "     \n",
    "    It returns the most common value in that column of that table.\n",
    "    In case of a tie, it returns any one of the most common values\n",
    "    \"\"\"\n",
    "    ...\n",
    "\n",
    "most_common('Genre', close_movies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congratulations are in order -- you've classified your first movie! You correctly classified Fast Times at Ridgemont High as a comedy! You are done with Lab 11! In class we will expand on how we can use many features to perform classification."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
